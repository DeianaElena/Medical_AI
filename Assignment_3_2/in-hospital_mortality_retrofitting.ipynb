{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"in-hospital_mortality_retrofitting.ipynb","provenance":[{"file_id":"https://github.com/mriosb08/AMC-NLP-Course/blob/master/mam11-2020/notebooks/in_hospital_mortality_retrofitting.ipynb","timestamp":1605259515930}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"-8elwvxUiHzt"},"source":["The task in this notebook is mortality prediction on 48hrs using physiological variables.\n","\n","The positive class is mortality and the negative survive.\n","\n","We define preprocessing, and test, training classes in python and pytorch. You have to complete the code and answer questions for the following exercises.\n","\n","## Exercises\n","\n","1.   Train word embeddings using retrofitting\n","2.   Visualize retrofitted embedding\n","  *   How the word2vec and retrofitted embeddings look like? \n","  *   What difference do you see and why?\n","3.   Train the model first using the word2vec embeddings and then retrofitted embeddings. Then evaluate both the trained models on the test set. \n","  * Do you see any difference?\n","  * Do results improve? \n","  * Compare the AUC and the calibration curves (with and without retrofitting).\n","  * **EXTRA** plot AUC and calibration curves for both models (with and without retrofitting) together\n","  * **EXTRA** Try different (larger and smaller) values for the parameters ```-n``` of retrofitting\n","      * Do the results change?\n","4. **EXTRA** Generate the lexicon for retrofitting using the additional notebook Named Entity Recognition with Scispacy"]},{"cell_type":"markdown","metadata":{"id":"8bSMdxdvj2Zd"},"source":["## Download data"]},{"cell_type":"code","metadata":{"id":"YQ-CZ0Mph_pP"},"source":["#dowload csv files from gdrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","# Authenticate and create the PyDrive client.\n","# This only needs to be done once per notebook.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"71EfVOVVV5j4"},"source":["#download file from gdrive with the id for share file\n","# create share link for tar.gz file  and copy id\n","#https://drive.google.com/file/d/1PV8SF2ToQ50QaFA435gXBw8UCXF6Zio9/view?usp=sharing\n","#3k patients\n","file_id = '1S4jRAEmI4mLNCNhT3Z06bM9nhPSTSkyE'\n","downloaded = drive.CreateFile({'id': file_id})\n","#3k patients\n","downloaded.GetContentFile('test_text_data_2.tar.gz')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F4k9lBdhWTsH"},"source":["#extract data\n","!tar -xzf test_text_data_2.tar.gz"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ttukgVDiVmlC"},"source":["**Pre-trained word embeddings** Embeddings generated from the clinical notes of the patients in the training set with word2vec."]},{"cell_type":"code","metadata":{"id":"kBABt4P-JUou"},"source":["#similarly for word embeddings\n","# https://drive.google.com/file/d/1i28MYb91_Gz2zB1c-5nExTLGOd9EhPQv/view?usp=sharing\n","file_id = '1b_XLXkNHdhLtI1pmgY9EsaTv-Y7s6fcW' # URL id. \n","downloaded = drive.CreateFile({'id': file_id})\n","downloaded.GetContentFile('mimic_vectors_training.100d.txt')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kLq6mf6OkPT8"},"source":["## Upload utils \n","**Upload mimic__utils_text.py**\n","For reading csv, normalize data, and imputation.\n","The imputation techinique used is setting missing values to the previous value, there are other imputation methods avilable. Extension of the utielities from the the [YerevaNN](https://github.com/YerevaNN/mimic3-benchmarks) framework to also use the clinical notes."]},{"cell_type":"code","metadata":{"id":"UGurxaL2jjH9","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":"OK"}},"base_uri":"https://localhost:8080/","height":75},"outputId":"e569ec0f-1734-4f03-e370-a0de197ecbc7"},"source":["#download mimic_utils_text config\n","#TODO add config into dataset\n","from google.colab import files\n","uploaded = files.upload()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-bdcb8050-fd14-4437-847d-88ef8bbc1a90\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-bdcb8050-fd14-4437-847d-88ef8bbc1a90\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving mimic_utils_text.py to mimic_utils_text.py\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yER9sgBaQ6AQ"},"source":["**Configuration files for mimic__utils_text.py** Files necessary to use mimic__utils_text.py. For more information see the [YerevaNN](https://github.com/YerevaNN/mimic3-benchmarks) framework."]},{"cell_type":"code","metadata":{"id":"SoiEq4_gZvVT","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":"OK"}},"base_uri":"https://localhost:8080/","height":75},"outputId":"cbdfa9d9-d004-43b7-b209-1c8ce02cc452"},"source":["#download discretizer config\n","#TODO add config into dataset\n","from google.colab import files\n","uploaded = files.upload()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-eca31c2d-a4d2-4a68-ad95-4a301f19c6b0\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-eca31c2d-a4d2-4a68-ad95-4a301f19c6b0\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving discretizer_config.json to discretizer_config.json\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eB4gprWnbcBg","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":"OK"}},"base_uri":"https://localhost:8080/","height":75},"outputId":"22fb7164-a9c5-4b7a-898a-d3402bc7dd7f"},"source":["#download normalizer config\n","#TODO add config into dataset\n","from google.colab import files\n","uploaded = files.upload()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-b16fd79d-65be-4f63-8fcd-c4100ad8335e\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-b16fd79d-65be-4f63-8fcd-c4100ad8335e\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving norm_start_time_zero.normalizer to norm_start_time_zero.normalizer\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"waP1sCNrP4Sb"},"source":["**Upload retrofit.py**\n","This file implements the retrofitting method seen in our class. More details and documentation are available [here](https://github.com/mfaruqui/retrofitting)."]},{"cell_type":"code","metadata":{"id":"UoCijLhtOo-8","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":"OK"}},"base_uri":"https://localhost:8080/","height":75},"outputId":"d3da342b-9437-43ae-e89b-99387c6fc9ff"},"source":["#download retrofitting\n","#TODO add config into dataset\n","from google.colab import files\n","uploaded = files.upload()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-70906ec4-74ea-4049-b9c2-781bdc233afc\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-70906ec4-74ea-4049-b9c2-781bdc233afc\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving retrofit.py to retrofit.py\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iE-ikQsnSNpy"},"source":["**Lexicon (knowledge graph) for to use for your experiment** This is a lexicon based on [UMLS](https://www.nlm.nih.gov/research/umls/index.html). Specifically:\n","  \n","\n","1.   Entities have been annotated from the clinical notes' of patients included in the training data;\n","2.   Annotated entities have been linked to UMLS concepts;\n","3.   Synonims from those UMLS concepts have been extracted (using the proper relation).\n","\n"]},{"cell_type":"code","metadata":{"id":"zurAgnvgTlb5","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":"OK"}},"base_uri":"https://localhost:8080/","height":75},"outputId":"85c1d357-f0c2-46d4-8284-283ccee110e8"},"source":["#download umls synonyms config\n","#TODO add config into dataset\n","from google.colab import files\n","uploaded = files.upload()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-113a37d0-99c7-42f0-ba86-0d9707e8a2d2\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-113a37d0-99c7-42f0-ba86-0d9707e8a2d2\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving lexicon_UMLS_synonyms.txt to lexicon_UMLS_synonyms.txt\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YUqZfvgPUwU5"},"source":["## Install dependencies"]},{"cell_type":"code","metadata":{"id":"5lnabeEAKay0"},"source":["!pip install stop_words"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k5BDFOhwSlVI"},"source":["## Run retrofit\n","Retrofit wordembeddings and generate new embeddings which takes UMLS synonyms into account.\n","Fill the command properly looking at its [documentation](https://github.com/mfaruqui/retrofitting). The retrofitted embeddings needs to be saved in a file named 'mimic_vectors_retrofitted.txt'"]},{"cell_type":"code","metadata":{"id":"HcU7IHi6SkeM","colab":{"base_uri":"https://localhost:8080/","height":72},"outputId":"7659d339-ecbc-4c7b-8180-614d81a63f65"},"source":["!python2 retrofit.py # COMPLETE HERE"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Vectors read from: mimic_vectors_training.100d.txt \n","\n","Writing down the vectors in mimic_vectors_retrofitted.txt\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GRIHWUoPkVV2"},"source":["## Import libraries"]},{"cell_type":"code","metadata":{"id":"FXZ7HWxhjeOD"},"source":["#import python and pytorch libraries\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.optim import Adam\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","import codecs\n","import os\n","import sys\n","import numpy as np\n","import logging\n","import tempfile\n","import shutil\n","import pickle\n","import platform\n","import json\n","from datetime import datetime\n","from nltk.corpus import stopwords\n","from stop_words import get_stop_words\n","from collections import defaultdict\n","import string\n","import random\n","from __future__ import absolute_import\n","from __future__ import print_function\n","from sklearn import metrics\n","from mimic_utils_text import InHospitalMortalityReader, Discretizer, Normalizer, read_chunk"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ohkz4_5D_naR"},"source":["## Visualize embeddings\n","Visualize word2vec using [T-distributed stochastic neighbor embedding (tSNE)](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding). \n","Vizualize also the retrofitted embeddings and  compare them with word2vec ones. How the word2vec and retrofitted embeddings look like? What difference do you see and why?"]},{"cell_type":"code","metadata":{"id":"CuctzjzYAHWp"},"source":["# load glove into gensim\n","from gensim.test.utils import datapath, get_tmpfile\n","from gensim.models import KeyedVectors\n","from gensim.scripts.glove2word2vec import glove2word2vec\n","import matplotlib.cm as cm\n","import matplotlib.pyplot as plt\n","from sklearn.manifold import TSNE\n","\n","glove_file = 'mimic_vectors_training.100d.txt'\n","tmp_file = get_tmpfile(\"glove_word2vec.txt\")\n","_ = glove2word2vec(glove_file, tmp_file)\n","model = KeyedVectors.load_word2vec_format(tmp_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JfNh-ooTAsaH"},"source":["def tsne_plot_similar_words(title, labels, embedding_clusters, word_clusters, a, filename=None):\n","    plt.figure(figsize=(16, 9))\n","    colors = cm.rainbow(np.linspace(0, 1, len(labels)))\n","    for label, embeddings, words, color in zip(labels, embedding_clusters, word_clusters, colors):\n","        x = embeddings[:, 0]\n","        y = embeddings[:, 1]\n","        plt.scatter(x, y, c=color, alpha=a, label=label)\n","        for i, word in enumerate(words):\n","            plt.annotate(word, alpha=0.5, xy=(x[i], y[i]), xytext=(5, 2),\n","                         textcoords='offset points', ha='right', va='bottom', size=8)\n","    plt.legend(loc=4)\n","    plt.title(title)\n","    plt.grid(True)\n","    if filename:\n","        plt.savefig(filename, format='png', dpi=150, bbox_inches='tight')\n","    plt.show()\n","\n","\n","#plot clusters in the same fig for word2vec\n","keys = ['diabetes', 'sepsis', 'pneumonia']\n","\n","embedding_clusters = []\n","word_clusters = []\n","for word in keys:\n","    embeddings = []\n","    words = []\n","    for similar_word, _ in model.most_similar(word, topn=20):\n","        words.append(similar_word)\n","        embeddings.append(model[similar_word])\n","    embedding_clusters.append(embeddings)\n","    word_clusters.append(words)\n","\n","embedding_clusters = np.array(embedding_clusters)\n","n, m, k = embedding_clusters.shape\n","tsne_model_en_2d = TSNE(perplexity=15, n_components=2, init='pca', n_iter=3500, random_state=32)\n","embeddings_en_2d = np.array(tsne_model_en_2d.fit_transform(embedding_clusters.reshape(n * m, k))).reshape(n, m, 2) \n","\n","tsne_plot_similar_words('Similar words from word2vec', keys, embeddings_en_2d, word_clusters, 0.7,\n","                        'similar_words_word2vec.png')\n","\n","# Your code here\n","# visualize retrofitted embeddings"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3S1iXwTTmr_l"},"source":["## Pytorch Dataset\n","\n","We define a vocabulary, dataset, acollate function and create batch \n"]},{"cell_type":"code","metadata":{"id":"p6_0T4_z29-p"},"source":["# vocabulary class to upload word2vec into pytorch\n","# default tokens\n","UNK_TOKEN = \"<unk>\"\n","PAD_TOKEN = \"<pad>\"\n","SOS_TOKEN = \"<s>\"\n","EOS_TOKEN = \"</s>\"\n","\n","\n","class Vocabulary:\n","    \"\"\"\n","        Creates a vocabulary from a word2vec file. \n","    \"\"\"\n","    def __init__(self):\n","        self.idx_to_word = {0: PAD_TOKEN, 1: UNK_TOKEN, 2: SOS_TOKEN, 3: EOS_TOKEN}\n","        self.word_to_idx = {PAD_TOKEN: 0, UNK_TOKEN: 1, SOS_TOKEN: 2, EOS_TOKEN: 3}\n","        self.word_freqs = {}\n","       \n","    \n","    def __getitem__(self, key):\n","        return self.word_to_idx[key] if key in self.word_to_idx else self.word_to_idx[UNK_TOKEN]\n","    \n","    def word(self, idx):\n","        return self.idx_to_word[idx]\n","    \n","    def size(self):\n","        return len(self.word_to_idx)\n","    \n","    \n","    def from_data(input_file, vocab_size, emb_size):\n","      \n","        vocab = Vocabulary()\n","        vocab_size = vocab_size + len(vocab.idx_to_word)\n","        weight = np.zeros((vocab_size, emb_size))\n","        with codecs.open(input_file, 'rb')  as f:\n","         \n","          for l in f:\n","            line = l.decode().split()\n","            token = line[0]\n","            if token not in vocab.word_to_idx:\n","              idx = len(vocab.word_to_idx)\n","              vocab.word_to_idx[token] = idx\n","              vocab.idx_to_word[idx] = token\n","            \n","              vect = np.array(line[1:]).astype(np.float)\n","              weight[idx] = vect\n","          # average embedding for unk word\n","          avg_embedding = np.mean(weight, axis=0)\n","          weight[1] = avg_embedding\n","                            \n","        return vocab, weight"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A8JTbfcomYc4"},"source":["\n","# pytroch class for reading data into batches\n","class MIMICTextDataset(Dataset):\n","    \"\"\"\n","       Loads a list of sentences into memory from a text file,\n","       split by newlines. \n","    \"\"\"\n","    def __init__(self, reader, discretizer, normalizer, \n","            notes_output='sentence', max_w=25, max_s=500, max_d=500,\n","            target_repl=False, batch_labels=False):\n","        self.data = []\n","        self.y  = []\n","        self.max_w = max_w\n","        self.max_s = max_s\n","        self.max_d = max_d\n","        N = reader.get_number_of_examples()\n","        #if small_part:\n","        #    N = 1000\n","        ret = read_chunk(reader, N)\n","        data = ret[\"X\"]\n","        notes_text = ret[\"text\"]\n","        notes_info = ret[\"text_info\"]\n","        ts = ret[\"t\"]\n","        labels = ret[\"y\"]\n","        names = ret[\"name\"]\n","        data = [discretizer.transform(X, end=t)[0] for (X, t) in zip(data, ts)]\n","        if normalizer is not None:\n","            data = [normalizer.transform(X) for X in data]\n","        #self.x = np.array(data, dtype=np.float32)\n","        #self.T = self.data.shape[1]\n","        #if target_repl:\n","        #    self.y = self._extend_labels(self.y)\n","        #notes into list of sentences, docs, etc..\n","        self.notes = []\n","        tmp_data = []\n","        tmp_labels = []\n","        if notes_output == 'sentence':\n","            # [N, W] patients, words\n","            for patient_notes, _x, l  in zip(notes_text, data, labels):\n","                tmp_notes = []\n","                for doc in sorted(patient_notes):\n","                    sentences = patient_notes[doc]\n","                    for sentence in sentences:\n","                        #print(sentence)\n","                        tmp_notes.extend(sentence)\n","                if len(tmp_notes) > 0 and len(tmp_notes) <= self.max_w:\n","                    #print(tmp_notes)\n","                    self.notes.append(' '.join(tmp_notes))\n","                    #self.notes.append(tmp_notes)\n","                    tmp_data.append(_x)\n","                    tmp_labels.append(l)\n","                #elif len(tmp_notes) > 0:\n","                #    self.notes.append(' '.join(tmp_notes[:self.max_w]))\n","                #    tmp_data.append(_x)\n","        elif notes_output == 'sentence-max':\n","             # [N, W] patients, words\n","             # [N, W] patients, words\n","            for patient_notes, _x, l  in zip(notes_text, data, labels):\n","                tmp_notes = []\n","                for doc in sorted(patient_notes):\n","                    sentences = patient_notes[doc]\n","                    for sentence in sentences:\n","                        #print(sentence)\n","                        tmp_notes.extend(sentence)\n","                if len(tmp_notes) > 0 and len(tmp_notes) <= self.max_w:\n","                    #print(tmp_notes)\n","                    self.notes.append(' '.join(tmp_notes))\n","                    #self.notes.append(tmp_notes)\n","                    tmp_data.append(_x)\n","                    tmp_labels.append(l)\n","                elif len(tmp_notes) > 0:\n","                    self.notes.append(' '.join(tmp_notes[:self.max_w]))\n","                    tmp_data.append(_x)\n","                    tmp_labels.append(l)\n","\n","        elif notes_output == 'doc':\n","            # [N, S, W] patients, sentences, words\n","            # TODO add max size!\n","            for patient_notes,  _x, l in zip(notes_text, data, labels):\n","                tmp_notes = []\n","                for doc in sorted(patient_notes):\n","                    sentences = patient_notes[doc]\n","                    for sentence in sentences:\n","                        if len(sentence) > 0 and len(sentence) <= max_w:\n","                            tmp_notes.append(sentence)\n","                        elif len(sentence) > 0:\n","                            tmp_notes.append(sentence[:max_w])\n","                if len(tmp_notes) > 0 and len(tmp_notes) <= max_s:\n","                    self.notes.append(tmp_notes)\n","                    tmp_data.append(_x)\n","                    tmp_labels.append(l)\n","                elif len(tmp_notes) > 0:\n","                    self.notes.append(tmp_notes[:max_s])\n","                    tmp_data.append(_x)\n","                    tmp_labels.append(l)\n","        \n","#\n","        self.x = np.array(tmp_data, dtype=np.float32)   \n","        self.T = self.x.shape[1]\n","        if batch_labels:\n","            self.y = np.array([[l] for l in tmp_labels], dtype=np.float32)\n","        else:\n","            self.y = np.array(tmp_labels, dtype=np.float32)\n","\n","\n","    def _extend_labels(self, labels):\n","        # (B,)\n","        labels = labels.repeat(self.T, axis=1)  # (B, T)\n","        return labels\n","\n","    def __len__(self):\n","        # overide len to get number of instances\n","        return len(self.x)\n","\n","    def __getitem__(self, idx):\n","        # get words and label for a given instance index\n","        return self.x[idx], self.notes[idx], self.y[idx]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pc8Qm4WA3QYT"},"source":["#collate and create batch for documents and sentences \n","\n","\n","def create_sentence_batch(sentences, vocab, device, stopwords=False):\n","    \"\"\"\n","    Converts a list of sentences to a padded batch of word ids. Returns\n","    an input batch, output tags, a sequence mask over\n","    the input batch, and a tensor containing the sequence length of each\n","    batch element.\n","    :param sentences: a list of sentences, each a list of token ids\n","    :param vocab: a Vocabulary object for this dataset\n","    :param device: \n","    :returns: a batch of padded inputs,  mask, lengths\n","    \"\"\"\n","    if stopwords:\n","        tok = np.array([_remove_stopwords(sen) for sen in sentences])\n","    else:\n","        tok = np.array([sen.split() for sen in sentences])\n","    #tok = np.array([sen[0] for sen in sentences])\n","    seq_lengths = [len(sen) for sen in tok]\n","    max_len = max(seq_lengths)\n","    pad_id = vocab[PAD_TOKEN]\n","    unk_id = vocab[UNK_TOKEN]\n","\n","    pad_id_input = []\n","    #pad and find ids for words given the word2vec vocab\n","    #print(tok)\n","    for idx, sen in enumerate(tok):\n","      tmp_sent = []\n","      for t in range(max_len):\n","        if t < seq_lengths[idx]:\n","          try:\n","            token_id = vocab[sen[t]]\n","          except KeyError:\n","            token_id = unk_id\n","        else:\n","          token_id = pad_id\n","        tmp_sent.append(token_id)\n","      pad_id_input.append(tmp_sent) \n","\n","    \n","    # Convert everything to PyTorch tensors.\n","    batch_input = torch.tensor(pad_id_input)\n","    seq_mask = (batch_input != vocab[PAD_TOKEN])\n","    seq_length = torch.tensor(seq_lengths)\n","    \n","    # Move all tensors to the given device.\n","    batch_input = batch_input.to(device)\n","    seq_mask = seq_mask.to(device)\n","    seq_length = seq_length.to(device)\n","    \n","    return batch_input, seq_mask, seq_length\n","\n","\n","def doc_collate(batch):\n","    data = np.array([item[0] for item in batch])\n","    data = torch.tensor(data)\n","    notes = [item[1] for item in batch]\n","    target = np.array([item[2] for item in batch])\n","    target = torch.tensor(target)\n","    #target = torch.LongTensor(target)\n","    return [data, notes, target]\n","\n","\n","def create_doc_batch(docs, vocab, device):\n","    \"\"\"\n","    \"\"\"\n","    sent_seq_lengths = np.array([len(doc) for doc in docs])\n","    word_seq_lengths = [[len(sent) for sent in doc] for doc in docs]\n","    b = len(docs)\n","    sent_max_len = max(sent_seq_lengths)\n","    word_max_len = max([max(w_seq) for w_seq in word_seq_lengths])\n","    pad_id = vocab[PAD_TOKEN]\n","    unk_id = vocab[UNK_TOKEN]\n","\n","    pad_id_input = np.zeros((b, sent_max_len, word_max_len), dtype=int)\n","    word_seq_length = np.ones((b, sent_max_len), dtype=np.float32)\n","    for i, w_lens in enumerate(word_seq_lengths):\n","        for j, w_len in enumerate(w_lens):\n","            word_seq_length[i][j] = w_len\n","    #pad and find ids for words given the word2vec vocab\n","    #print(tok)\n","    for idx_doc, doc in enumerate(docs):\n","        #tmp_doc = []\n","        for i in range(sent_max_len):\n","            tmp_sent = []\n","            if i < sent_seq_lengths[idx_doc]:\n","                sent = doc[i]\n","                for j in range(word_max_len):\n","                    if j < word_seq_lengths[idx_doc][i]:\n","                        try:\n","                            token_id = vocab[sent[j]]\n","                        except KeyError:\n","                            token_id = unk_id\n","                    else:\n","                        token_id = pad_id\n","                    #tmp_sent.append(token_id)\n","                    pad_id_input[idx_doc][i][j] = token_id\n","            else:\n","                #tmp_sent = [pad_id for _ in range(word_max_len[idx_doc])] \n","                for j in range(word_max_len):\n","                    pad_id_input[idx_doc][i][j] = pad_id\n","        #pad_id_input.append(tmp_sent) \n","\n","    # Convert everything to PyTorch tensors.\n","    batch_input = torch.tensor(pad_id_input)\n","    #seq_mask = (batch_input != vocab[PAD_TOKEN])\n","    sent_seq_length = torch.tensor(sent_seq_lengths)\n","    word_seq_length = torch.tensor(word_seq_length)\n","    \n","    # Move all tensors to the given device.\n","    batch_input = batch_input.to(device)\n","    #seq_mask = seq_mask.to(device)\n","    sent_seq_length = sent_seq_length.to(device)\n","    word_seq_length = word_seq_length.to(device)\n","    \n","    return batch_input, sent_seq_length, word_seq_length"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ikv2wdqEmxrZ"},"source":["## Evaluation metrics"]},{"cell_type":"code","metadata":{"id":"8qVNiqW1nJa7"},"source":["# eval metrics\n","def print_metrics_binary(y_true, predictions, logging, verbose=1):\n","    predictions = np.array(predictions)\n","    if len(predictions.shape) == 1:\n","        predictions = np.stack([1 - predictions, predictions]).transpose((1, 0))\n","    cf = metrics.confusion_matrix(y_true, predictions.argmax(axis=1))\n","    if verbose:\n","        logging.info(\"confusion matrix:\")\n","        logging.info(cf)\n","    cf = cf.astype(np.float32)\n","\n","    acc = (cf[0][0] + cf[1][1]) / np.sum(cf)\n","    prec0 = cf[0][0] / (cf[0][0] + cf[1][0])\n","    prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","    rec0 = cf[0][0] / (cf[0][0] + cf[0][1])\n","    rec1 = cf[1][1] / (cf[1][1] + cf[1][0])\n","    auroc = metrics.roc_auc_score(y_true, predictions[:, 1])\n","\n","    (precisions, recalls, thresholds) = metrics.precision_recall_curve(y_true, predictions[:, 1])\n","    auprc = metrics.auc(recalls, precisions)\n","    minpse = np.max([min(x, y) for (x, y) in zip(precisions, recalls)])\n","\n","    if verbose:\n","        logging.info(\"accuracy = {0:.3f}\".format(acc))\n","        logging.info(\"precision class 0 = {0:.3f}\".format(prec0))\n","        logging.info(\"precision class 1 = {0:.3f}\".format(prec1))\n","        logging.info(\"recall class 0 = {0:.3f}\".format(rec0))\n","        logging.info(\"recall class 1 = {0:.3f}\".format(rec1))\n","        logging.info(\"AUC of ROC = {0:.3f}\".format(auroc))\n","        logging.info(\"AUC of PRC = {0:.3f}\".format(auprc))\n","       \n","\n","    return {\"acc\": acc,\n","            \"prec0\": prec0,\n","            \"prec1\": prec1,\n","            \"rec0\": rec0,\n","            \"rec1\": rec1,\n","            \"auroc\": auroc,\n","            \"auprc\": auprc}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-2B6Q5Wwkvgk"},"source":["## Training\n","\n","Here we define the model, loss and training loop.\n","Train the model first using the word2vec embeddings and then retrofitted embeddings. Do you see any difference? (also evaluate the model once trained see below)"]},{"cell_type":"code","metadata":{"id":"pye3W2HkjoOp"},"source":["#model Bow with a single sequence for a patient\n","\n","class BoWText(nn.Module):\n","\n","    def __init__(self, vocab_size, label_size, emb_size, hidden_size, dropout=0.2, model_w2vec=None, bidirectional=False):\n","\n","        super().__init__()\n","        self.bidirectional = bidirectional\n"," #       self.pad_idx = pad_idx\n","\n","        weights = torch.FloatTensor(model_w2vec)\n","        self.embedder = nn.Embedding.from_pretrained(weights, freeze=False) \n","        #two experiments: freeze True/False (maybe it is good to update because Glove is general and our data is domain specific)\n","\n","        self.combination_layer = nn.Linear(emb_size, hidden_size)\n","\n","        self.projection = nn.Linear(hidden_size, label_size)\n","        self.relu = nn.ReLU()\n","        self.dropout_layer = nn.Dropout(p=dropout)\n","\n","    def forward(self, x, seq_mask, seq_len): #x=notes\n","\n","        # Compute word embeddings\n","        # [B,M,E] B=patient, M=sentence, E=emb\n","#        print(x.size())\n","        x_embed = self.embedder(x)\n","        #x_embed = self.dropout_layer(x_embed) #each word in the sentence is turned on/off for regulatization\n","        # [B, M, hid_size]\n","        h = self.combination_layer(x_embed)\n","        h = self.relu(h)\n","        h = self.dropout_layer(h)\n","        #mean\n","        #h = h.mean(dim=1)\n","        # average\n","        #print(seq_len.size())\n","        #print(torch.sum(h,dim=1).size())\n","        h = torch.sum(h, dim=1) / seq_len.unsqueeze(-1) #check mean syntax in pytorch --> [B,hidden_size]\n","\n","        logits = self.projection(h) #size [B,1] each patient has a logit mortality\n","        \n","        return logits"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BG63f4LBnFFf"},"source":["#eval model\n","def eval_model(model, dataset, device, vocab):\n","    model.eval()\n","    sigmoid = nn.Sigmoid()\n","    with torch.no_grad():\n","        y_true = []\n","        predictions = []\n","        for _, notes, labels  in dataset:\n","            labels = labels.to(device)\n","            x_notes, seq_mask, seq_len = create_sentence_batch(notes, \n","                    vocab, \n","                    device, \n","                    stopwords=False)\n","\n","            logits =  model(x_notes, seq_mask, seq_len)\n","            probs = sigmoid(logits)\n","            #_, predicted = torch.max(probs.data, 1)\n","            #y_hat_class = np.where(probs.data<0.5, 0, 1)\n","            predictions += [p.item() for p in probs]#y_hat_class.squeeze()\n","            y_true += [y.item() for y in labels]\n","    #print(predictions)\n","    #print(y_true)\n","    results = print_metrics_binary(y_true, predictions, logging)\n","    return results, predictions, y_true"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4WSyj4Minlc6"},"source":["def train(args):\n","  mode = 'train'\n","  hidden_size = args['dim']\n","  dropout = args['dropout']\n","  batch_size = args['batch_size']\n","  learning_rate = args['lr']\n","  num_epochs = args['epochs']\n","  emb_size = args['emb_size']\n","  aggregation_type = args['aggregation_type']\n","  bidirectional_encoder = args['bidirectional'] # TODO add into args\n","  seed = args['seed']\n","  steps = args['steps']\n","  data = args['data']\n","  notes = args['notes']\n","  word2vec = args['word2vec']\n","  max_w = args['max_w']\n","  timestep = args['timestep']\n","  normalizer_state = args['normalizer_state']\n","  vocab_size = args['vocab_size']\n","  if seed:\n","      torch.manual_seed(seed)\n","      np.random.seed(seed)\n","  device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")   \n","  \n","  logging.basicConfig(level=logging.INFO, \n","          format='%(asctime)s %(message)s', \n","          datefmt='%Y-%m-%d %H:%M:%S',\n","          )\n","  \n","  vocab, weight = Vocabulary.from_data(word2vec, vocab_size, emb_size) #glove 107647 400000, 300)\n","    #print(vocab)\n","    #rint(vocab[\"<unk>\"])\n","\n","  train_reader = InHospitalMortalityReader(dataset_dir=os.path.join(data, 'train'),\n","                                        notes_dir=notes,  \n","                                        listfile=os.path.join(data, 'train_listfile.csv'),\n","                                         period_length=48.0)\n","\n","  val_reader = InHospitalMortalityReader(dataset_dir=os.path.join(data, 'train'),\n","                                       notes_dir=notes,\n","                                       listfile=os.path.join(data, 'val_listfile.csv'),\n","                                       period_length=48.0)\n","\n","  discretizer = Discretizer(timestep=float(timestep),\n","                          store_masks=True,\n","                          impute_strategy='previous',\n","                          start_time='zero')\n","  discretizer_header = discretizer.transform(train_reader.read_example(0)[\"X\"])[1].split(',')\n","  cont_channels = [i for (i, x) in enumerate(discretizer_header) if x.find(\"->\") == -1]\n","\n","  normalizer = Normalizer(fields=cont_channels)  # choose here which columns to standardize\n","  normalizer_state = normalizer_state\n","  if normalizer_state is None:\n","      normalizer_state = 'norm_start_time_zero.normalizer'\n","      #normalizer_state = 'ihm_ts{}.input_str:{}.start_time:zero.normalizer'.format(args['timestep'], args['imputation'])\n","      #normalizer_state = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), normalizer_state)\n","  #print(normalizer_state)\n","  normalizer.load_params(normalizer_state)\n","\n","  # sentence option proces notes into single sequence\n","  train_dataset = MIMICTextDataset(train_reader, \n","                discretizer, \n","                normalizer, \n","                batch_labels=True,\n","                max_w=max_w,\n","                notes_output='sentence-max')\n","  train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","  \n","  val_dataset = MIMICTextDataset(val_reader, \n","            discretizer, \n","            normalizer, \n","            batch_labels=True,\n","            max_w=max_w,\n","            notes_output='sentence-max')\n","  val_dl = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","  \n","  # Define the classification model.\n","  model = BoWText(vocab_size=vocab.size(),\n","                        label_size=1, #label size = 1 because of the binary nature of the predictions(classification)\n","                        emb_size=emb_size, \n","                        hidden_size=hidden_size,\n","                        dropout=dropout,\n","                        model_w2vec=weight)\n","\n","  model = model.to(device)\n","  logging.info(args)\n","  logging.info(model)\n","\n","  # Define optimizer\n","  optimizer = Adam(model.parameters(), lr=learning_rate) \n","   \n","  criterion = nn.BCEWithLogitsLoss()\n","\n","  # path to best model save on disk\n","  best_model = 'best_model.pt'\n","  best_val_auc = 0.\n","\n","  results = []\n","\n","  step = 0\n","  num_batches = 0\n","  #training loop\n","  # loop over the epochs\n","  for epoch_num in range(1, num_epochs+1): \n","      loss_batch = .0\n","      num_batches = 0\n","      # loop over mini-batches\n","      for _, notes, labels  in train_dl:\n","          # x = x.to(device) structure data\n","          labels = labels.to(device)\n","          # to tensor\n","          x_notes, seq_mask, seq_len = create_sentence_batch(notes, \n","                    vocab, \n","                    device, \n","                    stopwords=False)\n","          # Model is in training mode (for dropout).\n","          model.train()\n","          optimizer.zero_grad()\n","       \n","          # run forward\n","          logits =  model(x_notes, seq_mask, seq_len)\n","          \n","          loss = criterion(logits, labels)\n","            \n","          loss_batch += loss.item()\n","          # Backpropagate and update the model weights.\n","          loss.backward()\n","          optimizer.step()\n","        \n","          num_batches += 1\n","        \n","          # Every 100 steps we evaluate the model and report progress.\n","          if step % steps == 0:\n","              logging.info(\"epoch (%d) step %d: training loss = %.2f\"% \n","                 (epoch_num, step, loss_batch/num_batches))\n","            \n","            \n","          step += 1\n","        \n","        \n","      metrics_results, _, _ = eval_model(model,\n","                                    val_dl,\n","                                    device,\n","                                    vocab)\n","      metrics_results['epoch'] = epoch_num\n","      results.append(metrics_results)\n","      if metrics_results['auroc'] > best_val_auc:\n","        best_val_auc = metrics_results['auroc']\n","        # save best model in disk\n","        torch.save(model.state_dict(), best_model)\n","        logging.info('best model AUC of ROC = %.3f'%(best_val_auc))\n","      logging.info(\"Finished epoch %d\" % (epoch_num))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZbOmZFUhsARx"},"source":["#execute training \n","#define hyperparameters\n","# Change the parameter here to use the retrofitted embedding\n","\n","args = {'dim':128,\n","        'dropout':0.2,\n","        'batch_size':64,\n","        'lr':1e-3, # for word emebeddings in clinical task better use 1e-4 to avoid forgetting\n","        'epochs':20,\n","        'emb_size':100,\n","        'aggregation_type':'mean',\n","        'bidirectional':False,\n","        'seed':42,\n","        'steps':50,\n","        'data':'test_text_data_2/in-hospital-mortality',\n","        'notes': 'test_text_data_2/train',\n","        'word2vec': 'mimic_vectors_training.100d.txt',\n","        'max_w': 10000,\n","        'timestep':1.0,\n","        'imputation':'previous',\n","        'normalizer_state':None,\n","        'vocab_size': 130212} # number of lines in the embedding file (word2vec parameter above)\n","train(args)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iYLLKMUtk4zz"},"source":["## Test\n","\n","Here we use the best validation model and run in test. Run prediction model both with the word2vec and the retrofitted embeddings. Do result improve? Compare the AUC and  the calibration curves (before and after retrofitting).\n"]},{"cell_type":"code","metadata":{"id":"G79PLqTHjy9p"},"source":["#test\n","\n","def test(args):\n","    # define trainning and validation datasets\n","    mode = 'test'\n","    hidden_size = args['dim']\n","    dropout = args['dropout']\n","    batch_size = args['batch_size']\n","    emb_size = args['emb_size']\n","    best_model = args['best_model']\n","    data = args['data']\n","    notes = args['notes']\n","    word2vec = args['word2vec']\n","    max_w = args['max_w']\n","    timestep = args['timestep']\n","    aggregation_type = args['aggregation_type']\n","    bidirectional_encoder = args['bidirectional'] # TODO add into args\n","    vocab_size = args['vocab_size']\n","    device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")   \n","    # 1. Get a unique working directory \n","    \n","    logging.basicConfig(level=logging.INFO, \n","            format='%(asctime)s %(message)s', \n","            datefmt='%Y-%m-%d %H:%M:%S')\n","    \n","    vocab, weight = Vocabulary.from_data(word2vec, vocab_size, emb_size) #glove 107647 400000, 300)\n","\n","    test_reader = InHospitalMortalityReader(dataset_dir=os.path.join(data, 'test'),\n","                                         listfile=os.path.join(data, 'test_listfile.csv'),\n","                                         notes_dir=notes, \n","                                         period_length=48.0)\n","\n","    \n","    discretizer = Discretizer(timestep=float(timestep),\n","                          store_masks=True,\n","                          impute_strategy='previous',\n","                          start_time='zero')\n","\n","    discretizer_header = discretizer.transform(test_reader.read_example(0)[\"X\"])[1].split(',')\n","    cont_channels = [i for (i, x) in enumerate(discretizer_header) if x.find(\"->\") == -1]\n","\n","    normalizer = Normalizer(fields=cont_channels)  # choose here which columns to standardize\n","    normalizer_state = args['normalizer_state']\n","    if normalizer_state is None:\n","        #normalizer_state = 'ihm_ts{}.input_str:{}.start_time:zero.normalizer'.format(args.timestep, args.imputation)\n","        #normalizer_state = os.path.join(os.path.dirname(__file__), normalizer_state)\n","        normalizer_state = 'norm_start_time_zero.normalizer'\n","    normalizer.load_params(normalizer_state)\n","\n","    # Read data\n","    vocab, weight = Vocabulary.from_data(word2vec, vocab_size, emb_size) #glove 107647 , 300)\n","    # sentence option proces notes into single sequences\n","    test_dataset = MIMICTextDataset(test_reader, \n","            discretizer, \n","            normalizer, \n","            batch_labels=True,\n","            max_w=max_w,\n","            notes_output='sentence-max')\n"," \n","    test_dl =  DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","\n","    # Define the classification model.\n","    model = BoWText(vocab_size=vocab.size(),\n","                        label_size=1, #label size = 1 because of the binary nature of the predictions(classification)\n","                        emb_size=emb_size, \n","                        hidden_size=hidden_size,\n","                        dropout=dropout,\n","                        model_w2vec=weight)\n","\n","    model.load_state_dict(torch.load(best_model))\n","    logging.info(model)\n","    model = model.to(device)\n","\n","    metrics_results, pred_probs, y_true = eval_model(model,\n","                                test_dl,\n","                                device,\n","                                vocab)\n","    return metrics_results, pred_probs, y_true\n","            "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x-e2oIZ8qMP-"},"source":["# Run test on best validation model\n","# Change the parameter here to use the retrofitted embedding\n","args = {'best_model':'best_model.pt',\n","        'dim':128,\n","        'dropout':0.2,\n","        'batch_size':16,\n","        'word2vec':'mimic_vectors_training.100d.txt',\n","        'emb_size':100,\n","        'aggregation_type':'mean',\n","        'bidirectional':False,\n","        'data':'test_text_data_2/in-hospital-mortality',\n","        'notes':'test_text_data_2/test',\n","        'timestep':1.0,\n","        'max_w':10000,\n","        'imputation':'previous',\n","        'normalizer_state':None,\n","        'vocab_size': 130212} # number of lines in the embedding file (word2vec parameter above)\n","metrics_results, pred_probs, y_true = test(args)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MMnyVBDXTGKG"},"source":["## Plots\n","\n","ROC and calibrations curves"]},{"cell_type":"code","metadata":{"id":"yh1hzWghxbHm"},"source":["# Figures ROC and calibration curve\n","import matplotlib.pyplot as plt\n","import sys\n","from sklearn.calibration import calibration_curve\n","import matplotlib.pyplot as plt\n","import matplotlib.lines as mlines\n","import matplotlib.transforms as mtransforms\n","import pickle\n","from sklearn import metrics"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_1kDW3kqjgAf"},"source":["# roc curve\n","bow_fpr, bow_tpr, bow_thresholds = metrics.roc_curve(y_true, pred_probs)\n","\n","# plot the roc curve for the model\n","plt.figure()\n","plt.ylim(0., 1.0)\n","plt.xlim(0.,1.0)\n","plt.plot(bow_fpr, bow_tpr, marker='.', label='BoW', color='darkorange')\n","plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n","# axis labels\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","# show the legend\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C509pB4Eh7mA"},"source":["#calibration curve\n","bow_y, bow_x = calibration_curve(y_true, pred_probs, n_bins=10)\n","plt.figure()\n","plt.ylim(0., 1.0)\n","plt.xlim(0.,1.0)\n","#fig, ax = plt.subplots()\n","# only these two lines are calibration curves\n","plt.plot(bow_x,bow_y, marker='^', linestyle=\"\", markersize=7, label='BoW', color='darkorange')\n","\n","plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n","\n","plt.xlabel('Mean predicted value')\n","plt.ylabel('Fraction of positives')\n","plt.legend()\n","plt.show()\n","\n","#plt.show()\n"],"execution_count":null,"outputs":[]}]}