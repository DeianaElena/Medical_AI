{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "in_hospital_mortality_text.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8elwvxUiHzt"
      },
      "source": [
        "The task in this notebook is mortality prediction on 48hrs using clinical notes.\n",
        "\n",
        "The positive class is mortality and the negative survive.\n",
        "\n",
        "We define preprocessing, and test, training classes in python and pytorch. You can use the preivous practical as an exmaple to complete this notebook\n",
        "\n",
        "# Exercises\n",
        "\n",
        "1. Check the file `test_text_data_2/train/20/20_notes.txt`\n",
        "   - Plot the bar char of the most top-35 most common words\n",
        "   - Which words do seem most relevant to you?\n",
        "1. For the mortality prediction model based on average word embeddings (Bag-of-Words, BoW)  \n",
        "  - Implement the missing layers in the constructor\n",
        "  - Implement the forward pass, note: the batch for loop is different, and you will need to call the function create sentence batch\n",
        "      - use mean of word embeddings to aggregate features for the classifier\n",
        "      - **EXTRA** use average of the sentence (sum over the word dimension / sequence lenght) instead of mean to agregate features.  note: that the sequence lenght (seq_len) variable contains the actual size of each sentence in the batch. In addition, to define the correct size of the seq_len matrix you have to expand it with: `seq_len.unsqueeze(-1)`\n",
        "      - **EXTRA** compare the AUC-ROC on test betweent the mean and average arregation\n",
        "  - Implement model selection \n",
        "  - Print the test results for all the metrics\n",
        "  - Plot AUC and calibration curves (for test data)\n",
        "  - **EXTRA** run 3 random BoW with mean models (set seed to None) and report mean and std of the AUC-ROC and AUC-PR. what do you observe?\n",
        "\n",
        "2. Unfreeze the word embeddings for the BoW model with mean \n",
        "  - Compare the AUC-ROC on the test with the freeze model. what do you observe? Which one is better?\n",
        "  - Change the learning rate to 1e-4 for the unfreeze model and compare AUC-ROC with the previous models. what do you observe? Which one is better?\n",
        "\n",
        "3. Implement the LSTM model instead of BoW\n",
        "  - Add a LSTM layer into the constructor. NOTE: we recommend w_max is 3000 words, but you can try to push the GPU (also it will be slower). A longer sequence would make RNNs unfeasible.\n",
        "  - Use the best setting from the previous experiment for freeze or unfreeze word embeddings\n",
        "  - Apply the LSTM after the word embedding.\n",
        "  - Use mean as the aggeration of the LSTM ouputs.\n",
        "  - Print the test results for all the metrics\n",
        "  - Plot AUC and calibration curves (for test data)\n",
        "  - Compare the AUC-ROC on the test with the best BoW model. what do you observe? Which one is better?\n",
        "  - Use bidirectional LSTM\n",
        "    - Compare the AUC-ROC on the test with the LSTM. what do you observe? Which one is better?\n",
        "4. Compare the AUC-ROC across, your best structued, BoW and LSTM models. what do you observe? Which one is better?\n",
        "5. **EXTRA** Train your own word embeddings with the extra glove example notebook.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bSMdxdvj2Zd"
      },
      "source": [
        "## Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ-CZ0Mph_pP"
      },
      "source": [
        "#dowload csv files from gdrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71EfVOVVV5j4"
      },
      "source": [
        "#download file from gdrive with the id for share file\n",
        "# create share link for tar.gz file  and copy id\n",
        "#https://drive.google.com/file/d/1E279yz7ZiZmok6qOYWlrWku1w7F13T5Q/view?usp=sharing\n",
        "file_id = '1E279yz7ZiZmok6qOYWlrWku1w7F13T5Q' # URL id. \n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('test_text_data_2.tar.gz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4k9lBdhWTsH"
      },
      "source": [
        "#extract data\n",
        "!tar -xzf test_text_data_2.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBABt4P-JUou"
      },
      "source": [
        "#download file with word embeddings\n",
        "# https://drive.google.com/file/d/1NV3TIOF0P4cKfZ0Iwl8F3bwMk5-FfUiQ/view?usp=sharing\n",
        "file_id = '1NV3TIOF0P4cKfZ0Iwl8F3bwMk5-FfUiQ' # URL id. \n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('mimic_vectors_training.100d.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFVOrxW2gJ2D"
      },
      "source": [
        "#check size of vacabulary\n",
        "!wc -l mimic_vectors_training.100d.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoiEq4_gZvVT",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "632d10d0-be51-4bb9-adae-72707b3e2314"
      },
      "source": [
        "#download discretizer config\n",
        "#TODO add config into dataset\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fe38e165-32d1-4644-b67a-591bcef971ed\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fe38e165-32d1-4644-b67a-591bcef971ed\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving discretizer_config.json to discretizer_config.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB4gprWnbcBg",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "168fcb87-9376-4fff-e85c-4a1517b537d4"
      },
      "source": [
        "#download normalizer config\n",
        "#TODO add config into dataset\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0c9e2f1a-4984-4873-9473-04631de927b1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0c9e2f1a-4984-4873-9473-04631de927b1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving norm_start_time_zero.normalizer to norm_start_time_zero.normalizer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLq6mf6OkPT8"
      },
      "source": [
        "## upload utils \n",
        "**Upload mimic__utils_text.py**\n",
        "For reading csv, normalize data, and imputation.\n",
        "imputation techinique is previous, there are other imputation methods avilable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGurxaL2jjH9",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "7c29f5d7-55ee-4154-8295-ecb2e81651ef"
      },
      "source": [
        "#download normalizer config\n",
        "#TODO add config into dataset\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e907852a-c1e8-46e8-9939-b684a1d97360\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e907852a-c1e8-46e8-9939-b684a1d97360\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving mimic_utils_text.py to mimic_utils_text.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lnabeEAKay0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "34de8f86-75bf-49d8-eaef-404069bebd1e"
      },
      "source": [
        "# install stop words, you can use the option in the create batch funciton to filter  funcitonal words\n",
        "!pip install stop_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: stop_words in /usr/local/lib/python3.6/dist-packages (2018.7.23)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRIHWUoPkVV2"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXZ7HWxhjeOD"
      },
      "source": [
        "#import python and pytorch libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import codecs\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import logging\n",
        "import tempfile\n",
        "import shutil\n",
        "import pickle\n",
        "import platform\n",
        "import json\n",
        "from datetime import datetime\n",
        "from nltk.corpus import stopwords\n",
        "from stop_words import get_stop_words\n",
        "from collections import defaultdict\n",
        "import string\n",
        "import random\n",
        "from __future__ import absolute_import\n",
        "from __future__ import print_function\n",
        "from sklearn import metrics\n",
        "from mimic_utils_text import InHospitalMortalityReader, Discretizer, Normalizer, read_chunk\n",
        "\n",
        "# Figures ROC and calibration curve\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "from sklearn.calibration import calibration_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.lines as mlines\n",
        "import matplotlib.transforms as mtransforms\n",
        "import pickle\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3S1iXwTTmr_l"
      },
      "source": [
        "## Pytorch Dataset\n",
        "\n",
        "We define a vocabulary, dataset, a collate function and create batch \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6_0T4_z29-p"
      },
      "source": [
        "# vocabulary class to upload word2vec into pytorch\n",
        "# default tokens\n",
        "UNK_TOKEN = \"<unk>\"\n",
        "PAD_TOKEN = \"<pad>\"\n",
        "SOS_TOKEN = \"<s>\"\n",
        "EOS_TOKEN = \"</s>\"\n",
        "\n",
        "\n",
        "class Vocabulary:\n",
        "    \"\"\"\n",
        "        Creates a vocabulary from a word2vec file. \n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "      # we add special tokens for padding, unknown word, start of sentence and end of sentence\n",
        "      # idx_to_word is a dictionary of ids to words\n",
        "      # word_to_idx is a dictionary from words to ids\n",
        "        self.idx_to_word = {0: PAD_TOKEN, 1: UNK_TOKEN, 2: SOS_TOKEN, 3: EOS_TOKEN}\n",
        "        self.word_to_idx = {PAD_TOKEN: 0, UNK_TOKEN: 1, SOS_TOKEN: 2, EOS_TOKEN: 3}\n",
        "        self.word_freqs = {}\n",
        "       \n",
        "    \n",
        "    def __getitem__(self, key):\n",
        "        return self.word_to_idx[key] if key in self.word_to_idx else self.word_to_idx[UNK_TOKEN]\n",
        "    \n",
        "    def word(self, idx):\n",
        "        return self.idx_to_word[idx]\n",
        "    \n",
        "    def size(self):\n",
        "        return len(self.word_to_idx)\n",
        "    \n",
        "    \n",
        "    def from_data(input_file, vocab_size, emb_size):\n",
        "      # we read the word embeddings file into memory \n",
        "      #and create the unknown word with the average of all the vocabulary\n",
        "        vocab = Vocabulary()\n",
        "        vocab_size = vocab_size + len(vocab.idx_to_word)\n",
        "        weight = np.zeros((vocab_size, emb_size))\n",
        "        with codecs.open(input_file, 'rb')  as f:\n",
        "         \n",
        "          for l in f:\n",
        "            line = l.decode().split()\n",
        "            token = line[0] # first position token\n",
        "            if token not in vocab.word_to_idx:\n",
        "              idx = len(vocab.word_to_idx)\n",
        "              vocab.word_to_idx[token] = idx\n",
        "              vocab.idx_to_word[idx] = token\n",
        "            \n",
        "              vect = np.array(line[1:]).astype(np.float) #all cols are the embeddings\n",
        "              weight[idx] = vect\n",
        "          # average embedding for unk word\n",
        "          avg_embedding = np.mean(weight, axis=0)\n",
        "          weight[1] = avg_embedding\n",
        "                            \n",
        "        return vocab, weight"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8JTbfcomYc4"
      },
      "source": [
        "\n",
        "# pytroch class for reading data into batches\n",
        "class MIMICTextDataset(Dataset):\n",
        "    \"\"\"\n",
        "       Loads a list of sentences into memory from a text file,\n",
        "       split by newlines. \n",
        "    \"\"\"\n",
        "    def __init__(self, reader, discretizer, normalizer, \n",
        "            notes_output='sentence', max_w=25, max_s=500, max_d=500,\n",
        "            target_repl=False, batch_labels=False):\n",
        "        self.data = []\n",
        "        self.y  = []\n",
        "        self.max_w = max_w\n",
        "        self.max_s = max_s\n",
        "        self.max_d = max_d\n",
        "        N = reader.get_number_of_examples()\n",
        "        #if small_part:\n",
        "        #    N = 1000\n",
        "        ret = read_chunk(reader, N)\n",
        "        data = ret[\"X\"]\n",
        "        notes_text = ret[\"text\"] # we also load the text data from MIMIC\n",
        "        notes_info = ret[\"text_info\"] # extra info form the text like category of a note\n",
        "        ts = ret[\"t\"]\n",
        "        labels = ret[\"y\"]\n",
        "        names = ret[\"name\"]\n",
        "        data = [discretizer.transform(X, end=t)[0] for (X, t) in zip(data, ts)]\n",
        "        if normalizer is not None:\n",
        "            data = [normalizer.transform(X) for X in data]\n",
        "        \n",
        "        #notes into list of sentences, docs, etc..\n",
        "        self.notes = []\n",
        "        tmp_data = []\n",
        "        tmp_labels = []\n",
        "        if notes_output == 'sentence':\n",
        "            # [N, W] patients, words\n",
        "            # we exclude patients that have more tan max_w words\n",
        "            for patient_notes, _x, l  in zip(notes_text, data, labels):\n",
        "                tmp_notes = []\n",
        "                for doc in sorted(patient_notes):\n",
        "                    sentences = patient_notes[doc]\n",
        "                    for sentence in sentences:\n",
        "                        #print(sentence)\n",
        "                        tmp_notes.extend(sentence)\n",
        "                if len(tmp_notes) > 0 and len(tmp_notes) <= self.max_w:\n",
        "                    #print(tmp_notes)\n",
        "                    self.notes.append(' '.join(tmp_notes))\n",
        "                    #self.notes.append(tmp_notes)\n",
        "                    tmp_data.append(_x)\n",
        "                    tmp_labels.append(l)\n",
        "                #elif len(tmp_notes) > 0:\n",
        "                #    self.notes.append(' '.join(tmp_notes[:self.max_w]))\n",
        "                #    tmp_data.append(_x)\n",
        "        elif notes_output == 'sentence-max':\n",
        "             # [N, W] patients, words\n",
        "             # we cut notes of each patient up to max_w words\n",
        "            for patient_notes, _x, l  in zip(notes_text, data, labels):\n",
        "                tmp_notes = []\n",
        "                for doc in sorted(patient_notes):\n",
        "                    sentences = patient_notes[doc]\n",
        "                    for sentence in sentences:\n",
        "                        #print(sentence)\n",
        "                        tmp_notes.extend(sentence)\n",
        "                if len(tmp_notes) > 0 and len(tmp_notes) <= self.max_w:\n",
        "                    #print(tmp_notes)\n",
        "                    self.notes.append(' '.join(tmp_notes))\n",
        "                    #self.notes.append(tmp_notes)\n",
        "                    tmp_data.append(_x)\n",
        "                    tmp_labels.append(l)\n",
        "                elif len(tmp_notes) > 0:\n",
        "                    self.notes.append(' '.join(tmp_notes[:self.max_w]))\n",
        "                    tmp_data.append(_x)\n",
        "                    tmp_labels.append(l)\n",
        "\n",
        "        elif notes_output == 'doc':\n",
        "            # [N, S, W] patients, sentences, words\n",
        "            # we cut notes into max sentences and each sentence into max words\n",
        "            for patient_notes,  _x, l in zip(notes_text, data, labels):\n",
        "                tmp_notes = []\n",
        "                for doc in sorted(patient_notes):\n",
        "                    sentences = patient_notes[doc]\n",
        "                    for sentence in sentences:\n",
        "                        if len(sentence) > 0 and len(sentence) <= max_w:\n",
        "                            tmp_notes.append(sentence)\n",
        "                        elif len(sentence) > 0:\n",
        "                            tmp_notes.append(sentence[:max_w])\n",
        "                if len(tmp_notes) > 0 and len(tmp_notes) <= max_s:\n",
        "                    self.notes.append(tmp_notes)\n",
        "                    tmp_data.append(_x)\n",
        "                    tmp_labels.append(l)\n",
        "                elif len(tmp_notes) > 0:\n",
        "                    self.notes.append(tmp_notes[:max_s])\n",
        "                    tmp_data.append(_x)\n",
        "                    tmp_labels.append(l)\n",
        "        \n",
        "#\n",
        "        self.x = np.array(tmp_data, dtype=np.float32)   \n",
        "        self.T = self.x.shape[1]\n",
        "        if batch_labels:\n",
        "            self.y = np.array([[l] for l in tmp_labels], dtype=np.float32)\n",
        "        else:\n",
        "            self.y = np.array(tmp_labels, dtype=np.float32)\n",
        "\n",
        "\n",
        "    def _extend_labels(self, labels):\n",
        "        # (B,)\n",
        "        labels = labels.repeat(self.T, axis=1)  # (B, T)\n",
        "        return labels\n",
        "\n",
        "    def __len__(self):\n",
        "        # overide len to get number of instances\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # get words and label for a given instance index\n",
        "        # note now we have 2 sources or modalities of data\n",
        "        # structured variables, text and labels\n",
        "        return self.x[idx], self.notes[idx], self.y[idx]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pc8Qm4WA3QYT"
      },
      "source": [
        "#collate and create batch for sentences \n",
        "\n",
        "# the following function takes a batch of words [B, W] and creates a batch to the GPU\n",
        "# the batch is transfomred into ids and padded \n",
        "def create_sentence_batch(sentences, vocab, device, stopwords=False):\n",
        "    \"\"\"\n",
        "    Converts a list of sentences to a padded batch of word ids. Returns\n",
        "    an input batch, output tags, a sequence mask over\n",
        "    the input batch, and a tensor containing the sequence length of each\n",
        "    batch element.\n",
        "    :param sentences: a list of sentences, each a list of token ids\n",
        "    :param vocab: a Vocabulary object for this dataset\n",
        "    :param device: \n",
        "    :returns: a batch of padded inputs,  mask, lengths\n",
        "    \"\"\"\n",
        "    # we can skip stop words from a sequence \n",
        "    if stopwords:\n",
        "        tok = np.array([_remove_stopwords(sen) for sen in sentences])\n",
        "    else:\n",
        "        tok = np.array([sen.split() for sen in sentences])\n",
        "    #tok = np.array([sen[0] for sen in sentences])\n",
        "    seq_lengths = [len(sen) for sen in tok]\n",
        "    max_len = max(seq_lengths)\n",
        "    pad_id = vocab[PAD_TOKEN]\n",
        "    unk_id = vocab[UNK_TOKEN]\n",
        "\n",
        "    pad_id_input = []\n",
        "    #pad and find ids for words given the word2vec vocab\n",
        "    #print(tok)\n",
        "    for idx, sen in enumerate(tok):\n",
        "      tmp_sent = []\n",
        "      for t in range(max_len):\n",
        "        if t < seq_lengths[idx]:\n",
        "          try:\n",
        "            token_id = vocab[sen[t]]\n",
        "          except KeyError:\n",
        "            token_id = unk_id\n",
        "        else:\n",
        "          token_id = pad_id\n",
        "        tmp_sent.append(token_id)\n",
        "      pad_id_input.append(tmp_sent) \n",
        "\n",
        "    \n",
        "    # Convert everything to PyTorch tensors.\n",
        "    batch_input = torch.tensor(pad_id_input)\n",
        "    seq_mask = (batch_input != vocab[PAD_TOKEN])\n",
        "    seq_length = torch.tensor(seq_lengths)\n",
        "    \n",
        "    # Move all tensors to the given device.\n",
        "    batch_input = batch_input.to(device)\n",
        "    seq_mask = seq_mask.to(device)\n",
        "    seq_length = seq_length.to(device)\n",
        "    \n",
        "    return batch_input, seq_mask, seq_length\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ikv2wdqEmxrZ"
      },
      "source": [
        "## Evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qVNiqW1nJa7"
      },
      "source": [
        "# eval metrics\n",
        "def print_metrics_binary(y_true, predictions, logging, verbose=1):\n",
        "    predictions = np.array(predictions)\n",
        "    if len(predictions.shape) == 1:\n",
        "        predictions = np.stack([1 - predictions, predictions]).transpose((1, 0))\n",
        "    cf = metrics.confusion_matrix(y_true, predictions.argmax(axis=1))\n",
        "    if verbose:\n",
        "        logging.info(\"confusion matrix:\")\n",
        "        logging.info(cf)\n",
        "    cf = cf.astype(np.float32)\n",
        "\n",
        "    acc = (cf[0][0] + cf[1][1]) / np.sum(cf)\n",
        "    prec0 = cf[0][0] / (cf[0][0] + cf[1][0])\n",
        "    prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n",
        "    rec0 = cf[0][0] / (cf[0][0] + cf[0][1])\n",
        "    rec1 = cf[1][1] / (cf[1][1] + cf[1][0])\n",
        "    auroc = metrics.roc_auc_score(y_true, predictions[:, 1])\n",
        "\n",
        "    (precisions, recalls, thresholds) = metrics.precision_recall_curve(y_true, predictions[:, 1])\n",
        "    auprc = metrics.auc(recalls, precisions)\n",
        "    minpse = np.max([min(x, y) for (x, y) in zip(precisions, recalls)])\n",
        "\n",
        "    if verbose:\n",
        "        logging.info(\"accuracy = {0:.3f}\".format(acc))\n",
        "        logging.info(\"precision class 0 = {0:.3f}\".format(prec0))\n",
        "        logging.info(\"precision class 1 = {0:.3f}\".format(prec1))\n",
        "        logging.info(\"recall class 0 = {0:.3f}\".format(rec0))\n",
        "        logging.info(\"recall class 1 = {0:.3f}\".format(rec1))\n",
        "        logging.info(\"AUC of ROC = {0:.3f}\".format(auroc))\n",
        "        logging.info(\"AUC of PRC = {0:.3f}\".format(auprc))\n",
        "       \n",
        "\n",
        "    return {\"acc\": acc,\n",
        "            \"prec0\": prec0,\n",
        "            \"prec1\": prec1,\n",
        "            \"rec0\": rec0,\n",
        "            \"rec1\": rec1,\n",
        "            \"auroc\": auroc,\n",
        "            \"auprc\": auprc}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j0H4HwTCx5U"
      },
      "source": [
        "## Understand the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMjuNAkNC0gL"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# read the file\n",
        "with open('test_text_data_2/train/20/20_note.txt','r') as f:\n",
        "  txt = f.read()\n",
        "# Exclude headers\n",
        "txt = re.sub(\"[0-9]+,[0-9]+,[0-9][0-9][0-9][0-9]-[0-1][0-9]-[0-3][0-9]\\s[0-2][0-9]:[0-5][0-9]:[0-9][0-9],[0-9][0-9][0-9][0-9]-[0-1][0-9]-[0-9][0-9]\\s[0-9][0-9]:[0-9][0-9]:[0-9][0-9],[0-9]+\\.[0-9][0-9]+,[0-9]+,[0-9]+\\.[0-9]+\\n\", \"\", txt)\n",
        "# tokenize\n",
        "txt = txt.split('\\n')\n",
        "# exclude puctuation\n",
        "txt = filter(lambda x: not re.match(r'^,|:|to|%|\\.|\\*+|\\[|\\]|\\(|\\)|\\^|\\s*$', x), txt)\n",
        "# exclude stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_sentence = [w for w in txt if not w.lower() in stop_words]\n",
        "# Your code here\n",
        "# Hint: you can use nltk.FreqDist and nltk.FreqDist.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2B6Q5Wwkvgk"
      },
      "source": [
        "## Training\n",
        "\n",
        "Here we define the model, loss and training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pye3W2HkjoOp"
      },
      "source": [
        "#model Bow with a single sequence for a patient\n",
        "\n",
        "class BoWText(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, label_size, emb_size, hidden_size, dropout=0.2, model_w2vec=None, bidirectional=False):\n",
        "\n",
        "        super().__init__()\n",
        "        self.bidirectional = bidirectional\n",
        "        # This is how the network uploads embeddings into the lookup layer\n",
        "        # numpy vectors into tensor\n",
        "        weights = torch.FloatTensor(model_w2vec)\n",
        "        # this embedder will be the encoder for the text notes \n",
        "        # freeze true means that is not going to update the parameters of the word embeddings\n",
        "        self.embedder = nn.Embedding.from_pretrained(weights, freeze=True) \n",
        "        # your code here\n",
        "        # add hidden combination layer\n",
        "        # add projection layer\n",
        "        # add dropout layer\n",
        "        # add relu activation function\n",
        "\n",
        "\n",
        "    def forward(self, x, seq_mask, seq_len): #x=notes\n",
        "        # your code here\n",
        "        # Compute word embeddings\n",
        "        # [B,W,E] B=patient, M=sentence, E=embedings\n",
        "        # apply dropout \n",
        "        # apply a hidden layer\n",
        "        # [B, W, hid_size]\n",
        "        # apply mean to aggregate features\n",
        "        # project features into logits \n",
        "        # [B,1] \n",
        "        \n",
        "        return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG63f4LBnFFf"
      },
      "source": [
        "#eval model\n",
        "def eval_model(model, dataset, device, vocab):\n",
        "    model.eval()\n",
        "    sigmoid = nn.Sigmoid()\n",
        "    with torch.no_grad():\n",
        "        y_true = []\n",
        "        predictions = []\n",
        "        for _, notes, labels  in dataset:\n",
        "            labels = labels.to(device)\n",
        "            x_notes, seq_mask, seq_len = create_sentence_batch(notes, \n",
        "                    vocab, \n",
        "                    device, \n",
        "                    stopwords=False)\n",
        "\n",
        "            logits =  model(x_notes, seq_mask, seq_len)\n",
        "            probs = sigmoid(logits)\n",
        "            #_, predicted = torch.max(probs.data, 1)\n",
        "            #y_hat_class = np.where(probs.data<0.5, 0, 1)\n",
        "            predictions += [p.item() for p in probs]#y_hat_class.squeeze()\n",
        "            y_true += [y.item() for y in labels]\n",
        "    #print(predictions)\n",
        "    #print(y_true)\n",
        "    results = print_metrics_binary(y_true, predictions, logging)\n",
        "    return results, predictions, y_true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WSyj4Minlc6"
      },
      "source": [
        "def train(args):\n",
        "  mode = 'train'\n",
        "  hidden_size = args['dim']\n",
        "  dropout = args['dropout']\n",
        "  batch_size = args['batch_size']\n",
        "  learning_rate = args['lr']\n",
        "  num_epochs = args['epochs']\n",
        "  emb_size = args['emb_size']\n",
        "  aggregation_type = args['aggregation_type']\n",
        "  bidirectional_encoder = args['bidirectional'] # TODO add into args\n",
        "  seed = args['seed']\n",
        "  steps = args['steps']\n",
        "  data = args['data']\n",
        "  notes = args['notes']\n",
        "  word2vec = args['word2vec']\n",
        "  max_w = args['max_w']\n",
        "  timestep = args['timestep']\n",
        "  normalizer_state = args['normalizer_state']\n",
        "  if seed:\n",
        "      torch.manual_seed(seed)\n",
        "      np.random.seed(seed)\n",
        "  device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")   \n",
        "  \n",
        "  logging.basicConfig(level=logging.INFO, \n",
        "          format='%(asctime)s %(message)s', \n",
        "          datefmt='%Y-%m-%d %H:%M:%S',\n",
        "          )\n",
        "  \n",
        "  vocab, weight = Vocabulary.from_data(word2vec, 130212, emb_size) #glove size vocabulary, emb size\n",
        "    #print(vocab)\n",
        "    #rint(vocab[\"<unk>\"])\n",
        "\n",
        "  train_reader = InHospitalMortalityReader(dataset_dir=os.path.join(data, 'train'),\n",
        "                                        notes_dir=notes,  \n",
        "                                        listfile=os.path.join(data, 'train_listfile.csv'),\n",
        "                                         period_length=48.0)\n",
        "\n",
        "  val_reader = InHospitalMortalityReader(dataset_dir=os.path.join(data, 'train'),\n",
        "                                       notes_dir=notes,\n",
        "                                       listfile=os.path.join(data, 'val_listfile.csv'),\n",
        "                                       period_length=48.0)\n",
        "\n",
        "  discretizer = Discretizer(timestep=float(timestep),\n",
        "                          store_masks=True,\n",
        "                          impute_strategy='previous',\n",
        "                          start_time='zero')\n",
        "  discretizer_header = discretizer.transform(train_reader.read_example(0)[\"X\"])[1].split(',')\n",
        "  cont_channels = [i for (i, x) in enumerate(discretizer_header) if x.find(\"->\") == -1]\n",
        "\n",
        "  normalizer = Normalizer(fields=cont_channels)  # choose here which columns to standardize\n",
        "  normalizer_state = normalizer_state\n",
        "  if normalizer_state is None:\n",
        "      normalizer_state = 'norm_start_time_zero.normalizer'\n",
        "     \n",
        "  normalizer.load_params(normalizer_state)\n",
        "\n",
        "  # sentence-max option proces notes into single sequence\n",
        "  train_dataset = MIMICTextDataset(train_reader, \n",
        "                discretizer, \n",
        "                normalizer, \n",
        "                batch_labels=True,\n",
        "                max_w=max_w,\n",
        "                notes_output='sentence-max')\n",
        "  train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "  \n",
        "  val_dataset = MIMICTextDataset(val_reader, \n",
        "            discretizer, \n",
        "            normalizer, \n",
        "            batch_labels=True,\n",
        "            max_w=max_w,\n",
        "            notes_output='sentence-max')\n",
        "  val_dl = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "  \n",
        "  # Define the classification model.\n",
        "  model = BoWText(vocab_size=vocab.size(),\n",
        "                        label_size=1, \n",
        "                        emb_size=emb_size, \n",
        "                        hidden_size=hidden_size,\n",
        "                        dropout=dropout,\n",
        "                        model_w2vec=weight)\n",
        "\n",
        "  model = model.to(device)\n",
        "  logging.info(args)\n",
        "  logging.info(model)\n",
        "\n",
        "  # Define optimizer\n",
        "  optimizer = Adam(model.parameters(), lr=learning_rate) \n",
        "   \n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "  # path to best model save on disk\n",
        "  best_model = 'best_model.pt'\n",
        "  best_val_auc = 0.\n",
        "\n",
        "  results = []\n",
        "\n",
        "  step = 0\n",
        "  num_batches = 0\n",
        "  # your code here\n",
        "  #training loop\n",
        "  # loop over the epochs\n",
        "  #for epoch_num... \n",
        "      #loss_batch = .0\n",
        "      #num_batches = 0\n",
        "      # loop over mini-batches note now we ignore x and use notes as input to create batch\n",
        "      #for _, notes, labels  in train_dl:\n",
        "          # use create sentence batch to make batch tensors for input for your model\n",
        "          #x_notes, seq_mask, seq_len = create_sentence_batch(notes, \n",
        "          #          vocab, \n",
        "          #          device, \n",
        "          #          stopwords=False)\n",
        "          \n",
        "          # run forward\n",
        "          # Backpropagate and update the model weights.\n",
        "         \n",
        "        \n",
        "          # Every x steps we evaluate the model and report progress.\n",
        "          if step % steps == 0:\n",
        "              logging.info(\"epoch (%d) step %d: training loss = %.2f\"% \n",
        "                 (epoch_num, step, loss_batch/num_batches))\n",
        "            \n",
        "            \n",
        "          step += 1\n",
        "        \n",
        "        \n",
        "      metrics_results, _, _ = eval_model(model,\n",
        "                                    val_dl,\n",
        "                                    device,\n",
        "                                    vocab)\n",
        "      metrics_results['epoch'] = epoch_num\n",
        "      results.append(metrics_results)\n",
        "      #Your code here\n",
        "      # model selection\n",
        "      \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbOmZFUhsARx"
      },
      "source": [
        "#execute training \n",
        "#define hyperparameters\n",
        "\n",
        "args = {'dim':128,\n",
        "        'dropout':0.2,\n",
        "        'batch_size':64,\n",
        "        'lr':1e-3,\n",
        "        'epochs':20,\n",
        "        'emb_size':100, # from our pretrained embeddings\n",
        "        'aggregation_type':'mean',\n",
        "        'bidirectional':False,\n",
        "        'seed':42, # set to None for random model\n",
        "        'steps':50,\n",
        "        'data':'test_text_data_2/in-hospital-mortality',\n",
        "        'notes': 'test_text_data_2/train',\n",
        "        'word2vec': '', #file with word embeddings\n",
        "        'max_w': 10000, # note change for LSTM and BiLSTM models\n",
        "        'timestep':1.0,\n",
        "        'imputation':'previous',\n",
        "        'normalizer_state':None}\n",
        "train(args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYLLKMUtk4zz"
      },
      "source": [
        "## Test\n",
        "\n",
        "Here we use the best validation model and run in test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G79PLqTHjy9p"
      },
      "source": [
        "#test\n",
        "\n",
        "def test(args):\n",
        "    # define trainning and validation datasets\n",
        "    mode = 'test'\n",
        "    hidden_size = args['dim']\n",
        "    dropout = args['dropout']\n",
        "    batch_size = args['batch_size']\n",
        "    emb_size = args['emb_size']\n",
        "    best_model = args['best_model']\n",
        "    data = args['data']\n",
        "    notes = args['notes']\n",
        "    word2vec = args['word2vec']\n",
        "    max_w = args['max_w']\n",
        "    timestep = args['timestep']\n",
        "    aggregation_type = args['aggregation_type']\n",
        "    bidirectional_encoder = args['bidirectional'] # TODO add into args\n",
        "    device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")   \n",
        "    # 1. Get a unique working directory \n",
        "    \n",
        "    logging.basicConfig(level=logging.INFO, \n",
        "            format='%(asctime)s %(message)s', \n",
        "            datefmt='%Y-%m-%d %H:%M:%S')\n",
        "    \n",
        "    vocab, weight = Vocabulary.from_data(word2vec, 130212, emb_size) #glove \n",
        "\n",
        "    test_reader = InHospitalMortalityReader(dataset_dir=os.path.join(data, 'test'),\n",
        "                                         listfile=os.path.join(data, 'test_listfile.csv'),\n",
        "                                         notes_dir=notes, \n",
        "                                         period_length=48.0)\n",
        "\n",
        "    \n",
        "    discretizer = Discretizer(timestep=float(timestep),\n",
        "                          store_masks=True,\n",
        "                          impute_strategy='previous',\n",
        "                          start_time='zero')\n",
        "\n",
        "    discretizer_header = discretizer.transform(test_reader.read_example(0)[\"X\"])[1].split(',')\n",
        "    cont_channels = [i for (i, x) in enumerate(discretizer_header) if x.find(\"->\") == -1]\n",
        "\n",
        "    normalizer = Normalizer(fields=cont_channels)  # choose here which columns to standardize\n",
        "    normalizer_state = args['normalizer_state']\n",
        "    if normalizer_state is None:\n",
        "        #normalizer_state = 'ihm_ts{}.input_str:{}.start_time:zero.normalizer'.format(args.timestep, args.imputation)\n",
        "        #normalizer_state = os.path.join(os.path.dirname(__file__), normalizer_state)\n",
        "        normalizer_state = 'norm_start_time_zero.normalizer'\n",
        "    normalizer.load_params(normalizer_state)\n",
        "\n",
        "    # Read data\n",
        "    vocab, weight = Vocabulary.from_data(word2vec, 107647, emb_size) #glove 107647 , 300)\n",
        "    # sentence option proces notes into single sequences\n",
        "    test_dataset = MIMICTextDataset(test_reader, \n",
        "            discretizer, \n",
        "            normalizer, \n",
        "            batch_labels=True,\n",
        "            max_w=max_w,\n",
        "            notes_output='sentence-max')\n",
        " \n",
        "    test_dl =  DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "    # Define the classification model.\n",
        "    model = BoWText(vocab_size=vocab.size(),\n",
        "                        label_size=1, #label size = 1 because of the binary nature of the predictions(classification)\n",
        "                        emb_size=emb_size, \n",
        "                        hidden_size=hidden_size,\n",
        "                        dropout=dropout,\n",
        "                        model_w2vec=weight)\n",
        "\n",
        "    model.load_state_dict(torch.load(best_model))\n",
        "    logging.info(model)\n",
        "    model = model.to(device)\n",
        "\n",
        "    metrics_results, pred_probs, y_true = eval_model(model,\n",
        "                                test_dl,\n",
        "                                device,\n",
        "                                vocab)\n",
        "    return metrics_results, pred_probs, y_true\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-e2oIZ8qMP-"
      },
      "source": [
        "# Run test on best validation model\n",
        "# note use same hyper parameters as in training\n",
        "args = {'best_model':'best_model.pt',\n",
        "        'dim':128,\n",
        "        'dropout':0.2,\n",
        "        'batch_size':16,\n",
        "        'word2vec':'', #file with word embeddings\n",
        "        'emb_size':100,\n",
        "        'aggregation_type':'mean',\n",
        "        'bidirectional':False,\n",
        "        'data':'test_text_data_2/in-hospital-mortality',\n",
        "        'notes':'test_text_data_2/test',\n",
        "        'timestep':1.0,\n",
        "        'max_w':10000,\n",
        "        'imputation':'previous',\n",
        "        'normalizer_state':None}\n",
        "metrics_results, pred_probs, y_true = test(args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMnyVBDXTGKG"
      },
      "source": [
        "## Plots\n",
        "\n",
        "ROC and calibrations curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1kDW3kqjgAf"
      },
      "source": [
        "# roc curve\n",
        "bow_fpr, bow_tpr, bow_thresholds = metrics.roc_curve(y_true, pred_probs)\n",
        "\n",
        "# plot the roc curve for the model\n",
        "plt.figure()\n",
        "plt.ylim(0., 1.0)\n",
        "plt.xlim(0.,1.0)\n",
        "plt.plot(bow_fpr, bow_tpr, marker='.', label='BoW', color='darkorange')\n",
        "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
        "# axis labels\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "# show the legend\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C509pB4Eh7mA"
      },
      "source": [
        "#calibration curve\n",
        "bow_y, bow_x = calibration_curve(y_true, pred_probs, n_bins=10)\n",
        "plt.figure()\n",
        "plt.ylim(0., 1.0)\n",
        "plt.xlim(0.,1.0)\n",
        "#fig, ax = plt.subplots()\n",
        "# only these two lines are calibration curves\n",
        "plt.plot(bow_x,bow_y, marker='^', linestyle=\"\", markersize=7, label='BoW', color='darkorange')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
        "\n",
        "plt.xlabel('Mean predicted value')\n",
        "plt.ylabel('Fraction of positives')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}